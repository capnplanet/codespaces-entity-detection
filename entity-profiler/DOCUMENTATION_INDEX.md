# Entity Profiler Documentation Index

This repository contains comprehensive documentation for the Entity Profiler platform. All documentation is grounded in the actual codebase with no false or misleading statements.

## üìò Core Documentation

### **[PLATFORM_CAPABILITIES.md](PLATFORM_CAPABILITIES.md)** - Comprehensive Technical Reference ‚≠ê
**1,316 lines | 6,298 words | Feynman-style explanation**

A complete, in-depth analysis of all platform capabilities, organized as requested:

#### Module-by-Module Function Analysis (18 Modules)
1. Vision Module: Person Detection
2. Vision Module: Pose Estimation  
3. Vision Module: Soft Biometrics
4. Vision Module: Clothing Features
5. Gait Module: Movement Analysis
6. Feature Fusion Module
7. Tracking Module
8. Entity Clustering and Profiling
9. Pattern-of-Life Analysis
10. Health Monitoring: Rules Engine
11. Health Monitoring: Fall Detection (Heuristic + Model)
12. Health Monitoring: Activity Level Detection
13. Health Monitoring: Posture Classification
14. Safety Monitoring: Rules Engine
15. Wearable Integration
16. Event System and Notifications
17. API Endpoints
18. Command-Line Interfaces

#### Special Focus Sections (As Requested)

**Gait and Movement Analysis - Detailed Examination**
- Purpose and scope
- Step-by-step algorithm breakdown
- Torso length normalization methodology
- Spatial statistics (mean coordinates, standard deviations)
- Velocity calculation and speed metrics
- Feature vector assembly (10 dimensions)
- Mobility assessment capabilities
- Activity level classification (speed ranges)
- Gait consistency interpretation
- Posture transitions and fall detection integration
- Camera angle dependencies
- Occlusion handling
- Temporal resolution requirements

**Predictive Qualities of Each Module**
- Person detection: accuracy metrics, factors affecting performance
- Pose estimation: precision and localization error
- Gait speed proxy: correlation with real-world metrics
- Fall detection: sensitivity, specificity, confusion matrix
- Pattern-of-life: maturity timelines and predictive applications
- Wearable-enhanced monitoring: multimodal fusion value

**Module Interactions and Complementary Functions**
- Complete interaction flow diagram
- 7 key complementary relationships:
  1. Detection ‚Üí Pose ‚Üí Gait (movement analysis chain)
  2. Soft Biometrics + Clothing + Gait (re-identification)
  3. Tracker + Clustering (identity maintenance)
  4. Pattern-of-Life + Rules (anomaly detection)
  5. Vision + Wearables (sensor fusion)
  6. Heuristic + Model fall detection (redundancy)
  7. Real-Time API + Batch CLI (deployment flexibility)

**Predictive Qualities When Integrated in Workflows**
- Real-time monitoring workflow (120-365ms latency)
- Batch analysis workflow (retrospective)
- Longitudinal monitoring (days to months)
- Statistical significance requirements
- Trend analysis methods

#### Additional Comprehensive Sections
- Configuration and calibration guidance
- Privacy, ethics, and limitations
- Deployment requirements
- What the platform predicts (immediate, short-term, medium-term, long-term)
- What the platform does NOT predict
- Confidence and reliability analysis

---

## üìÅ Additional Documentation Files

### Repository Documentation
- **[README.md](README.md)** - Quickstart guide, current API surfaces, and high-level capabilities
- **[docs/system_architecture.md](docs/system_architecture.md)** - End-to-end architecture including API, camera registry, wearables, events, and deployment
- **[docs/pattern_of_life.md](docs/pattern_of_life.md)** - Behavioral pattern analysis and how summaries are used by rules
- **[docs/profiling_pipeline.md](docs/profiling_pipeline.md)** - Processing pipeline from ingest through tracking, clustering, and rules
- **[docs/data_model.md](docs/data_model.md)** - Core data structures (observations, profiles, events, wearables, cameras, users)
- **[docs/determinism_and_reproducibility.md](docs/determinism_and_reproducibility.md)** - Deterministic behavior, seeding, and non-deterministic boundaries
- **[docs/examples.md](docs/examples.md)** - API, RTSP, wearable, and dashboard examples
- **[docs/state_of_the_art_and_comparison.md](docs/state_of_the_art_and_comparison.md)** - Positioning relative to VMS and multimodal health monitoring
- **[docs/use_cases_and_impact.md](docs/use_cases_and_impact.md)** - Example deployment scenarios and impact framing

### Example Scripts
- **[examples/api_usage.md](examples/api_usage.md)** - API usage examples
- **[examples/sample_video_pairs.md](examples/sample_video_pairs.md)** - Test data information
- **[examples/fitbit_pull.py](examples/fitbit_pull.py)** - Wearable data ingestion
- **[examples/rtsp_puller.py](examples/rtsp_puller.py)** - Camera stream ingestion
- **[examples/dashboard.html](examples/dashboard.html)** - Web dashboard

---

## üîç Key Technical Specifications (Validated)

All specifications below are directly grounded in source code:

### Feature Dimensions
- **Gait Features**: 10 dimensions (mean_x, mean_y, std_x, std_y, speed_mean, speed_std, num_poses, torso_length, 2√ó reserved)
- **Soft Biometrics**: 3 dimensions (height, aspect_ratio, area)
- **Clothing Features**: 80 dimensions (64 color histogram + 16 texture histogram)
- **Fused Features**: 93 dimensions (10+3+80)

### Default Thresholds
- **Gait Speed (Low Mobility)**: 0.05 (normalized units)
- **Fall Detection (Heuristic)**: height_ratio ‚â§ 0.35, aspect_increase ‚â• 1.8, area_increase ‚â• 0.25
- **Fall Detection (Model)**: score ‚â• 0.6 (weights: 0.4 height + 0.3 aspect + 0.2 speed + 0.1 area)
- **Tracker Similarity**: 0.7 (cosine similarity)
- **Tracker Max Age**: 3.0 seconds
- **Entity Clustering Distance**: 1.5 (Euclidean in 93D space)
- **No Activity Threshold**: 8.0 hours
- **Night Activity**: 5 observations during 0-6 AM window
- **Linger Detection**: 120.0 seconds
- **Wearable HR High**: 110 bpm, **HR Low**: 45 bpm, **SpO2 Low**: 92%

### Pose Estimation
- **Keypoints**: 17 (COCO format: nose, eyes, ears, shoulders, elbows, wrists, hips, knees, ankles)
- **Input Size**: 256√ó256 pixels
- **BBox Expansion**: 1.2√ó for context capture

### Detection
- **Primary**: HOG (Histogram of Oriented Gradients) + SVM
- **Optional**: ONNX neural network detector (1√ó3√ó640√ó640 input)
- **NMS Threshold**: 0.35 (IoU-based suppression)

---

## üìä Document Statistics

- **Primary Documentation**: PLATFORM_CAPABILITIES.md
- **Total Lines**: 1,316
- **Total Words**: 6,298
- **Major Sections**: 11
- **Detailed Subsections**: 39
- **Code References**: All specifications validated against source
- **False/Misleading Statements**: 0 (all grounded in actual code)

---

## üéØ Quick Navigation

| What You Need | Go To |
|---------------|-------|
| **Complete technical reference** | [PLATFORM_CAPABILITIES.md](PLATFORM_CAPABILITIES.md) |
| **Gait analysis details** | [PLATFORM_CAPABILITIES.md - Gait Section](PLATFORM_CAPABILITIES.md#gait-and-movement-analysis-detailed-examination) |
| **Predictive capabilities** | [PLATFORM_CAPABILITIES.md - Predictive Section](PLATFORM_CAPABILITIES.md#predictive-qualities-and-integration) |
| **Module interactions** | [PLATFORM_CAPABILITIES.md - Interactions Section](PLATFORM_CAPABILITIES.md#module-interactions-and-complementary-functions) |
| **Quick start guide** | [README.md](README.md) |
| **API usage** | [examples/api_usage.md](examples/api_usage.md) |
| **Configuration** | [PLATFORM_CAPABILITIES.md - Config Section](PLATFORM_CAPABILITIES.md#configuration-and-calibration) |

---

**Documentation Version**: 1.0  
**Last Updated**: 2026-01-13  
**Repository**: [capnplanet/codespaces-entity-detection](https://github.com/capnplanet/codespaces-entity-detection)
